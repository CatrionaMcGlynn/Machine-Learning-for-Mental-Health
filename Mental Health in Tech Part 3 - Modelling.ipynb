{"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"markdown","source":["# Mental Health in Tech Part 3 - Modelling\nExported from Filament on Sun, 13 Mar 2022 17:31:02 GMT\n\n---"],"metadata":{}},{"cell_type":"markdown","source":["This workbook applies a random forest model and logistic regression model for predicting what factors in the workplace most influence a person seeking treatment for their mental health. "],"metadata":{}},{"cell_type":"markdown","source":[""],"metadata":{}},{"cell_type":"markdown","source":["**Data import and cleaning**"],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["df = pd.read_csv(\"survey.csv\")"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["def invalid_entries(df):\n    ''' Function to identify invalid responses '''\n    \n    return np.where(((df['Age']<18)|(df['Age']>75))&\n           (df['self_employed']=='Yes')&\n           (df['family_history']=='Yes')&\n           (df['treatment']=='Yes')&\n           (df['work_interfere']=='Often')&\n           (df['no_employees']=='1-5')&\n           (df['remote_work']=='Yes')&\n           (df['tech_company']=='Yes')&\n           (df['benefits']=='Yes')&\n           (df['care_options']=='Yes')&\n           (df['wellness_program']=='Yes')&\n           (df['seek_help']=='Yes')&\n           (df['anonymity']=='Yes')&\n           (df['leave']=='Very easy')&\n           (df['mental_health_consequence']=='Yes')&\n           (df['phys_health_consequence']=='Yes')&\n           (df['coworkers']=='Yes')&\n           (df['supervisor']=='Yes')&\n           (df['mental_health_interview']=='Yes')&\n           (df['phys_health_interview']=='Yes')&\n           (df['mental_vs_physical']=='Yes')&\n           (df['obs_consequence']=='Yes'))"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["invalid_entries(df)"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["def check_duplicates(df):\n    ''' check for duplicates in dataset with Timestamp column excluded '''\n    exclude_col = ['Timestamp']\n    include_cols = [x for x in df.columns if x not in exclude_col]\n    return np.where(df[include_cols].duplicated() == True)"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["check_duplicates(df)"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["# Drop the 6 redundant rows from dataframe: \n\ndf.drop(df.index[[1127,989,821,860,1134,1218]],inplace=True)\n\nif df.shape[0]!=(1259-6):  # 1259 = original number of rows\n    raise Exception(f'unexpected number of rows: {df.shape[0]}')\n\ndf.reset_index(inplace=True)"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["def invalid_ages(age):\n    ''' Function to return entries with ages outside valid age range '''\n    return np.where((age<18)|(age>75))"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["invalid_ages(df['Age'])"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["# Replace invalid ages with median age from train, 31\n\ndf.loc[[143,364,390,715,734,1087],'Age']=31\n\n# Check dataframe\n\ndf[['Age']].iloc[[143,364,390,715,734,1087]]"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["# Group genders\n\nMale = ['Male', 'male', 'M', 'm']\nFemale = ['Female', 'female', 'F', 'f']\n\nOther = [x for x in df.Gender.unique() if x not in Male and x not in Female]\n\n# Replace all Gender values with Male, Female or Other\n\ndf['Gender'] = df['Gender'].replace(Male,'Male')\ndf['Gender'] = df['Gender'].replace(Female,'Female')\ndf['Gender'] = df['Gender'].replace(Other,'Other')\n\ndf['Gender'].unique()"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["countries = ['United States', 'United Kingdom'] # country categories to keep\n\nOther = [x for x in df.Country.unique() if x not in countries] \n\ndf['Country'] = df['Country'].replace(Other,'Other') # combine remaining\n\ndf['Country'].unique()"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"markdown","source":["**Feature engineering**"],"metadata":{}},{"cell_type":"code","source":["exclude = ['index','Timestamp','Age','state','comments']\n\ninclude = [x for x in df.columns if x not in exclude]\n\nfor col in include:\n    print(col, df[col].unique())"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["df['self_employed'] = df['self_employed'].fillna('No')\ndf['work_interfere'] = df['work_interfere'].fillna(0)\n\nif df['self_employed'].isnull().sum() == 0:\n    print(\"There are no nulls in the self_employed column\")\nif df['work_interfere'].isnull().sum() ==0:\n    print(\"There are no nulls in the work_interfere column\")"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["# Making data fields numerical\n\n\ndf.Gender.replace(('Male', 'Other', 'Female'), (-1, 0, 1), inplace=True)\n\ndf.Country.replace(('United States', 'United Kingdom', 'Other'), (1, 0, -1), inplace=True)\n\n\n\nyn_cols = ['self_employed', 'family_history', 'treatment', 'remote_work',\n               'tech_company','obs_consequence']\n\nfor col in yn_cols:\n    df[col].replace(('Yes', 'No'), (1, 0), inplace=True)\n    \n\n\ndk_cols = ['benefits', 'wellness_program', 'seek_help', 'anonymity', 'mental_vs_physical']\n\nfor col in dk_cols:\n    df[col].replace(('Yes', 'Don\\'t know', 'No'), (1, 0, -1), inplace=True)\n    \n\n\nmb_cols = ['mental_health_consequence', 'phys_health_consequence', \n           'mental_health_interview', 'phys_health_interview']\n\nfor col in mb_cols:\n    df[col].replace(('Yes', 'Maybe', 'No'), (1, 0, -1), inplace=True)\n\n\n    \nsm_cols = ['coworkers', 'supervisor']\n\nfor col in sm_cols:\n    df[col].replace(('Yes', 'Some of them', 'No'), (1, 0, -1), inplace=True)\n    \n\n\ndf['care_options'].replace(('Yes', 'Not sure', 'No'), (1, 0, -1), inplace=True)\n\ndf['no_employees'].replace(('1-5', '6-25', '26-100', '100-500', '500-1000', \n                            'More than 1000'), (1, 2, 3, 4, 5, 6), inplace=True)\n\ndf['work_interfere'].replace(('Never', 'Rarely', 'Sometimes', 'Often'), (1, 2, 3, 4), inplace=True)\n\ndf['leave'].replace(('Don\\'t know', 'Very easy', 'Somewhat easy', \n                     'Somewhat difficult', 'Very difficult'), (0, 1, 2, 3, 4), inplace=True)"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["sns.heatmap(df[include].corr(), annot=False)\nplt.show()"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"markdown","source":["**Train-test split**"],"metadata":{}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["model_df = df[df['work_interfere'] != (0)]\n\nnon_feature_cols = ['index','Timestamp','state','comments','treatment']\n\nfeature_cols = [x for x in df.columns if x not in non_feature_cols]"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(model_df[feature_cols], \n                                                    model_df['treatment'], # target variable\n                                                    test_size = 0.2, # 20%\n                                                    random_state = 1)"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["X_train['Age'].median()"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"markdown","source":["**Representative test set?**"],"metadata":{}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["train = X_train.copy()\ntest = X_test.copy()\n\n# Create new target\ntrain['train'] = 1\ntest['train'] = 0\n\n# Concatenate test and train\ntrain_test = pd.concat([train, test], axis = 0)\ntrain_test[['train','Age']].groupby('train').count()"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["# Define dependent and independent variables\ny = train_test['train']\nX = train_test.drop('train', axis =1)\n\n# Model\nrfc = RandomForestClassifier(n_estimators=10, random_state=1)\nrfc.fit(X, y)"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["# Cross validation\ncv_results = cross_val_score(rfc, X, y, cv=5, scoring='roc_auc')\nprint('Cross validation results:', cv_results)\nprint('Average:', np.mean(cv_results))\nprint('Difference from 0.5:', 0.5-np.mean(cv_results))\n\n# close to 0.5, therefore representative"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"markdown","source":[""],"metadata":{}},{"cell_type":"markdown","source":["# Random Forest"],"metadata":{}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics, tree"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["#Fitting our model\ndt = DecisionTreeClassifier(max_depth=3, \n                            min_samples_leaf=2, \n                            min_samples_split=5, \n                            random_state=1) # dt variable name for decision tree"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["#Fitting our chosen model using train data\ndt.fit(X_train, y_train)"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["#Target variables - the models predictor classes\ndt.classes_"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["#Plotting our tree\n\nfig = plt.figure(figsize=(15,10))\npicture = tree.plot_tree(dt, \n                   feature_names=feature_cols,  \n                   class_names=['no','yes'],\n                   filled=True)\n\nplt.show()"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["# model accurcay on train and test\nprint(f'Score on training set: {dt.score(X_train, y_train)}')\nprint(f'Score on testing set: {dt.score(X_test, y_test)}')"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["# Feature importance\nimportance = list(zip(feature_cols, list(dt.feature_importances_)))\nimportance.sort(key = lambda x:x[1], reverse = True)\n\nimportant = []\nfor f in importance:\n    if f[1] > 0:\n        important.append(f) # excludes unimportant/unused features in model\n\nprint('Features used in classification model in order of decreasing importance: ')\nimportant"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"markdown","source":["## Bagging"],"metadata":{}},{"cell_type":"code","source":["rf = RandomForestClassifier(random_state=1)"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["## Gridsearch used to tune hyperparameters\n\nrf_params = {\n    'n_estimators': [50, 100, 150],\n    'max_depth': [3, 4, 5],\n} \n# these test values were chosen based on previous testing with lower max depths\n\n\ngs = GridSearchCV(rf, param_grid=rf_params, scoring='precision', cv=10)\n\ngs.fit(X_train, y_train)\n\nprint(gs.best_score_)\n\ngs.best_params_"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nrf.fit(X_train, y_train)"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"markdown","source":["### Evaluation"],"metadata":{}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, accuracy_score"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["## defining function\n\ndef apr(y_pred, y_real):\n    \" Function returns the accurcay, precision, and recall of model predictions \"\n    accuracy = metrics.accuracy_score(y_real, y_pred)\n    precision = metrics.precision_score(y_real, y_pred)\n    recall = metrics.recall_score(y_real, y_pred)\n    f1 = metrics.f1_score(y_real, y_pred)\n    \n    print(f\"Accuracy:{accuracy}\")\n    print(f\"Precision:{precision}\")\n    print(f\"Recall:{recall}\")\n    print(f\"F1:{f1}\")\n    return accuracy, precision, recall, f1\n\n\n## defining function \n\ndef produce_confusion(positive_label, negative_label, cut_off, df, y_pred_name, y_real_name):\n    \" Function returns confusion matrix \"\n    #Set pred to 0 or 1 depending on whether it's higher than the cut_off point.\n    \n    if cut_off != 'binary':      \n        df['pred_binary'] = np.where(df[y_pred_name] > cut_off , 1, 0)\n    else: \n        df['pred_binary'] = df[y_pred_name]\n    \n    #Build the CM\n    cm = confusion_matrix(df[y_real_name], df['pred_binary'])  \n    \n    ax= plt.subplot()\n    sns.heatmap(cm, annot=True, ax=ax, fmt='g'); \n\n    # labels, title, ticks\n    ax.set_xlabel('Predicted labels');ax.set_ylabel('Real labels'); \n    ax.set_title('Confusion Matrix'); \n    ax.xaxis.set_ticklabels([negative_label, positive_label])\n    ax.yaxis.set_ticklabels([negative_label, positive_label]);\n\n    print('Test accuracy = ', accuracy_score(df[y_real_name], df['pred_binary']))\n\n    return accuracy_score(df[y_real_name], df['pred_binary'])"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["## Predict on Train\n## Check Accuracy, Precision, Recall & F1\n\npredictions_rf_train = pd.DataFrame(index=X_train.index)\n\npredictions_rf_train['Pred'] = gs.predict(X_train)\npredictions_rf_train['Actual'] = y_train\npredictions_rf_train['Prob'] = gs.predict_proba(X_train)[:,1]\n\napr(predictions_rf_train['Pred'],predictions_rf_train['Actual'])"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["## Predict on Test\n## Check Accuracy, Precision, Recall & F1\n\npredictions_rf_test = pd.DataFrame(index=X_test.index)\n\npredictions_rf_test['Pred'] = gs.predict(X_test)\npredictions_rf_test['Actual'] = y_test\npredictions_rf_test['Prob'] = gs.predict_proba(X_test)[:,1]\n\napr(predictions_rf_test['Pred'],predictions_rf_test['Actual'])"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["# Confusion matrix on train data\nproduce_confusion('Yes', 'No', 'binary', predictions_rf_train, 'Pred', 'Actual')"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["# Confusion matrix on test data\nproduce_confusion('Yes', 'No', 'binary', predictions_rf_test, 'Pred', 'Actual')"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["# Feature importance\nimportance = list(zip(feature_cols, list(rf.feature_importances_)))\nimportance.sort(key = lambda x:x[1], reverse = True)\nprint('Features listed in order of decreasing importance: ')\nimportance"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"markdown","source":[""],"metadata":{}},{"cell_type":"markdown","source":["# Logistic regression"],"metadata":{}},{"cell_type":"code","source":["import statsmodels.api as sm #modelling logistic regression"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["X_train = sm.add_constant(X_train)\nX_test = sm.add_constant(X_test)\ny_train = list(y_train)\ny_test = list(y_test)"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["# Model fitting\nlg_reg_MN = sm.MNLogit(y_train, X_train).fit()"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["# Model Summary\nlg_reg_MN.summary()"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"markdown","source":["### Logistic regression evaluation"],"metadata":{}},{"cell_type":"code","source":["#Model predictions\ntrain_pred_MN = lg_reg_MN.predict(X_train)\ntest_pred_MN = lg_reg_MN.predict(X_test)"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["# make probabilitites binary with cutoff 0.5\n\n# train\ntrain_pred_MN['Pred']  = (train_pred_MN[1].values > 0.5)\ntrain_pred_MN['Pred'].replace((True, False),(1, 0),inplace=True)\n\n# test\ntest_pred_MN['Pred']  = (test_pred_MN[1].values > 0.5)\ntest_pred_MN['Pred'].replace((True, False),(1, 0),inplace=True)"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["# train\napr(train_pred_MN['Pred'],y_train)"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["# test\napr(test_pred_MN['Pred'],y_test)"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["train_pred_MN['Actual'] = y_train\ntest_pred_MN['Actual'] = y_test"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["# Confusion matrix on train data\nproduce_confusion('Yes', 'No', 'binary', train_pred_MN, 'Pred', 'Actual')"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"code","source":["# Confusion matrix on test data\nproduce_confusion('Yes', 'No', 'binary', test_pred_MN, 'Pred', 'Actual')"],"outputs":[],"metadata":{},"execution_count":null},{"cell_type":"markdown","source":[""],"metadata":{}},{"cell_type":"markdown","source":["# Conclusions"],"metadata":{}},{"cell_type":"markdown","source":["* Models perform similarly in terms of accuracy (\\~0.8); random forest performs slightly better in terms of recall and logistic regression in terms of precision. \n\n* The degree to which mental health interfered with work was a strong predictor of seeking treatment, followed by a family history of mental illness. \n\n* Random forest model identified care options provided by employer as the third most significant feature in someone seeking treatment.\n\n* Improvement to logistic regression model and additional classification models may be employed to produce a better model. "],"metadata":{}},{"cell_type":"markdown","source":[""],"metadata":{}}],"metadata":{"createdWith":"Filament"}}